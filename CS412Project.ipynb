{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 412 Project\n",
    "Alaa Almouradi    \n",
    "Omar Mirza    \n",
    "Saleh Alshurafa    \n",
    "Abbas Ali Hakeem    \n",
    "M. Safwan Yasin    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Plan:    \n",
    "1. Extract features from the data to see what features perform better    \n",
    "2. Train-test split with shuffled data    \n",
    "3. Select models and perform hyper parameter tuning to get best results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature extraction:\n",
    "1. Question Presence:\n",
    "- vectorize the questions of the assignment after cleaning them\n",
    "- for each conversation: \n",
    "    - get number of prompts\n",
    "    - get average length of prompt\n",
    "    - for each response from chatgpt:\n",
    "        - clean it\n",
    "        - vectorize it\n",
    "        - measure similarity between response and questions\n",
    "        - add the similarity to each question as a column in the row\n",
    "2. Representative similarity (unused but implemented):\n",
    "- sort the scores\n",
    "- make a representative vector for each 20% segment in the ordered scores\n",
    "- for each conversation:\n",
    "    - clean it\n",
    "    - vectorize it\n",
    "    - measure similarity between response and the 5 representative vectors\n",
    "    - add the similarity to each representative vector as a column in the row\n",
    "3. Keyword count:\n",
    "- for each conversation:\n",
    "    - count selected keywords in prompts and responses and use the count for each keyword as a feature\n",
    "4. Calculated features:\n",
    "- features calculated from previous features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\Documents\\..UNIFiles\\.Senior(2023-2024)\\Fall\\CS412\\CS412-PROJECT\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.spatial import distance\n",
    "import spacy\n",
    "spacynlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import os\n",
    "import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning and vectorizing the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"\"\"Initialize\n",
    "*   First make a copy of the notebook given to you as a starter.\n",
    "*   Make sure you choose Connect form upper right.\n",
    "*   You may upload the data to the section on your left on Colab, than right click on the .csv file and get the path of the file by clicking on \"Copy Path\". You will be using it when loading the data.\n",
    "\n",
    "\"\"\",\n",
    "#####################\n",
    "    \"\"\"Load training dataset (5 pts)\n",
    "    *  Read the .csv file with the pandas library\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Understanding the dataset & Preprocessing (15 pts)\n",
    "Understanding the Dataset: (5 pts)\n",
    "> - Find the shape of the dataset (number of samples & number of attributes). (Hint: You can use the **shape** function)\n",
    "> - Display variable names (both dependent and independent).\n",
    "> - Display the summary of the dataset. (Hint: You can use the **info** function)\n",
    "> - Display the first 5 rows from training dataset. (Hint: You can use the **head** function)\n",
    "Preprocessing: (10 pts)\n",
    "\n",
    "> - Check if there are any missing values in the dataset. If there are, you can either drop these values or fill it with most common values in corresponding rows. **Be careful that you have enough data for training the  model.**\n",
    "\n",
    "> - Encode categorical labels with the mappings given in the cell below. (Hint: You can use **map** function)\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Set X & y, split data (5 pts)\n",
    "\n",
    "*   Shuffle the dataset.\n",
    "*   Seperate your dependent variable X, and your independent variable y. The column health_metrics is y, the rest is X.\n",
    "*   Split training and test sets as 80%\\ and 20%, respectively.\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Features and Correlations (10 pts)\n",
    "\n",
    "* Correlations of features with health (4 points)\n",
    "Calculate the correlations for all features in dataset. Highlight any strong correlations with the target variable. Plot your results in a heatmap.\n",
    "\n",
    "* Feature Selection (3 points)\n",
    "Select a subset of features that are likely strong predictors, justifying your choices based on the computed correlations.\n",
    "\n",
    "* Hypothetical Driver Features (3 points)\n",
    "Propose two hypothetical features that could enhance the model's predictive accuracy for Y, explaining how they might be derived and their expected impact. Show the resulting correlations with target variable.\n",
    "\n",
    "* __Note:__ You get can get help from GPT.\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Tune Hyperparameters (20 pts)\n",
    "* Choose 2 hyperparameters to tune. You can use the Scikit learn decision tree documentation for the available hyperparameters *(Hyperparameters are listed under \"Parameters\" in the documentation)*. Use GridSearchCV for hyperparameter tuning, with a cross-validation value of 5. Use validation accuracy to pick the best hyper-parameter values. (15 pts)\n",
    "-Explain the hyperparameters you chose to tune. *(What are the hyperparameters you chose? Why did you choose them?)* (5 pts)\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Re-train and plot the decision tree with the hyperparameters you have chosen (15 pts)\n",
    "- Re-train model with the hyperparameters you have chosen in part 5). (10 pts)\n",
    "- Plot the tree you have trained. (5 pts)\n",
    "Hint: You can import the **plot_tree** function from the sklearn library.\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Test your classifier on the test set (20 pts)\n",
    "- Predict the labels of testing data using the tree you have trained in step 6. (10 pts)\n",
    "- Report the classification accuracy. (2 pts)\n",
    "- Plot & investigate the confusion matrix. Fill the following blanks. (8 pts)\n",
    "> The model most frequently mistakes class(es) _________ for class(es) _________.\n",
    "Hint: You can use the confusion_matrix function from sklearn.metrics\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Find the information gain on the first split (10 pts)\"\"\",\n",
    "#####################\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [ i.lower().translate(str.maketrans('','',string.punctuation+\"\\n\")) for i in questions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionsVectorized = [spacynlp(question).vector for question in questions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:14<00:00,  8.67it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/html/*.html\"\n",
    "\n",
    "code2convos = dict()\n",
    "\n",
    "pbar = tqdm.tqdm(sorted(list(glob(data_path))))\n",
    "for path in pbar:\n",
    "    # print(Path.cwd() / path)\n",
    "    file_code = os.path.basename(path).split(\".\")[0]\n",
    "    with open(path, \"r\", encoding=\"latin1\") as fh:\n",
    "            \n",
    "        # get the file id to use it as key later on\n",
    "        fid = os.path.basename(path).split(\".\")[0]\n",
    "\n",
    "        # read the html file\n",
    "        html_page = fh.read()\n",
    "\n",
    "        # parse the html file with bs4 so we can extract needed stuff\n",
    "        soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "\n",
    "        # grab the conversations with the data-testid pattern\n",
    "        data_test_id_pattern = re.compile(r\"conversation-turn-[0-9]+\")\n",
    "        conversations = soup.find_all(\"div\", attrs={\"data-testid\": data_test_id_pattern})\n",
    "\n",
    "        convo_texts = []\n",
    "\n",
    "        for i, convo in enumerate(conversations):\n",
    "            convo = convo.find_all(\"div\", attrs={\"data-message-author-role\":re.compile( r\"[user|assistant]\") })\n",
    "            if len(convo) > 0:\n",
    "                role = convo[0].get(\"data-message-author-role\")\n",
    "                convo_texts.append({\n",
    "                        \"role\" : role,\n",
    "                        \"text\" : convo[0].text\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "        code2convos[file_code] = convo_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "code2responses = defaultdict(list)\n",
    "for code , convos in code2convos.items():\n",
    "    GPTresponses = []\n",
    "    for conv in convos:\n",
    "        if conv[\"role\"] == \"assistant\":   \n",
    "            GPTresponses.append(conv[\"text\"])\n",
    "    code2responses[code] = GPTresponses   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the scores\n",
    "scores = pd.read_csv(\"data/scores.csv\", sep=\",\")\n",
    "scores[\"code\"] = scores[\"code\"].apply(lambda x: x.strip())\n",
    "\n",
    "# selecting the columns we need and we care\n",
    "scores = scores[[\"code\", \"grade\"]].dropna()\n",
    "code2grade = dict()\n",
    "for code, grade in scores.to_dict(\"tight\")[\"data\"]:\n",
    "    code2grade[code] = grade\n",
    "len(code2grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question Presence and Representative vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order the scores\n",
    "scores.sort_values(by=[\"grade\"], inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a representative vector for each fifth\n",
    "pentileVectors = []\n",
    "for i in range (5):\n",
    "    pentile = np.zeros((300,))\n",
    "    for j in scores.iloc[i*(scores.shape[0]//5):(i+1)*(scores.shape[0]//5)][\"code\"]:\n",
    "        try:\n",
    "            responses = code2responses[j]\n",
    "        except:\n",
    "            continue\n",
    "        responsesVector = np.zeros((300,))\n",
    "        for response in responses:\n",
    "            responseClean = response.lower().translate(str.maketrans('','',string.punctuation+\"\\n\"))\n",
    "        \n",
    "            responsesVector += spacynlp(responseClean).vector/len(responses)\n",
    "        pentile += responsesVector/((i+1)*(scores.shape[0]//5)-i*(scores.shape[0]//5)+1)\n",
    "    pentileVectors.append(pentile)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalDataFrame = pd.DataFrame({i:[] for i in ([\"code\",\"response count\",\"avg. response length\" ]+[\"top \"+str(l)+\" fifth similarity\" for l in range(1,6)]+[\"Q\"+str(k)+\" presence\" for k in range(1,10)]+[str(j) for j in range(300)]+[\"grade\"])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>response count</th>\n",
       "      <th>avg. response length</th>\n",
       "      <th>top 1 fifth similarity</th>\n",
       "      <th>top 2 fifth similarity</th>\n",
       "      <th>top 3 fifth similarity</th>\n",
       "      <th>top 4 fifth similarity</th>\n",
       "      <th>top 5 fifth similarity</th>\n",
       "      <th>Q1 presence</th>\n",
       "      <th>Q2 presence</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0031c86e-81f4-4eef-9e0e-28037abf9883</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2218.500000</td>\n",
       "      <td>0.228392</td>\n",
       "      <td>0.191977</td>\n",
       "      <td>0.222714</td>\n",
       "      <td>0.252982</td>\n",
       "      <td>0.236511</td>\n",
       "      <td>0.004812</td>\n",
       "      <td>0.004353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127357</td>\n",
       "      <td>0.718181</td>\n",
       "      <td>0.408075</td>\n",
       "      <td>-0.466869</td>\n",
       "      <td>1.120409</td>\n",
       "      <td>0.290087</td>\n",
       "      <td>-2.362462</td>\n",
       "      <td>-2.166914</td>\n",
       "      <td>0.800465</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0225686d-b825-4cac-8691-3a3a5343df2b</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1653.111111</td>\n",
       "      <td>0.241666</td>\n",
       "      <td>0.203096</td>\n",
       "      <td>0.199066</td>\n",
       "      <td>0.258552</td>\n",
       "      <td>0.228758</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026360</td>\n",
       "      <td>0.877823</td>\n",
       "      <td>0.268821</td>\n",
       "      <td>-0.697356</td>\n",
       "      <td>0.702574</td>\n",
       "      <td>-0.085298</td>\n",
       "      <td>-2.083180</td>\n",
       "      <td>-2.442652</td>\n",
       "      <td>0.730275</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>041f950b-c013-409a-a642-cffff60b9d4b</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1636.222222</td>\n",
       "      <td>0.214095</td>\n",
       "      <td>0.222064</td>\n",
       "      <td>0.195110</td>\n",
       "      <td>0.198025</td>\n",
       "      <td>0.204584</td>\n",
       "      <td>0.003501</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.377180</td>\n",
       "      <td>0.958535</td>\n",
       "      <td>0.182306</td>\n",
       "      <td>-0.683194</td>\n",
       "      <td>0.959546</td>\n",
       "      <td>0.093472</td>\n",
       "      <td>-1.553406</td>\n",
       "      <td>-2.531710</td>\n",
       "      <td>1.012053</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04f91058-d0f8-4324-83b2-19c671f433dc</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1749.900000</td>\n",
       "      <td>0.316619</td>\n",
       "      <td>0.253115</td>\n",
       "      <td>0.265028</td>\n",
       "      <td>0.346919</td>\n",
       "      <td>0.317167</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075040</td>\n",
       "      <td>0.877138</td>\n",
       "      <td>0.494181</td>\n",
       "      <td>-0.608385</td>\n",
       "      <td>0.767160</td>\n",
       "      <td>0.088354</td>\n",
       "      <td>-2.170721</td>\n",
       "      <td>-2.184763</td>\n",
       "      <td>0.783525</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>089eb66d-4c3a-4f58-b98f-a3774a2efb34</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1455.441860</td>\n",
       "      <td>0.322102</td>\n",
       "      <td>0.274355</td>\n",
       "      <td>0.251310</td>\n",
       "      <td>0.300782</td>\n",
       "      <td>0.290301</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.906641</td>\n",
       "      <td>0.053110</td>\n",
       "      <td>-0.689573</td>\n",
       "      <td>0.772215</td>\n",
       "      <td>-0.106348</td>\n",
       "      <td>-1.679737</td>\n",
       "      <td>-2.382376</td>\n",
       "      <td>0.748501</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f24219d6-07f0-4baf-80ac-18475dc5b66f</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1818.285714</td>\n",
       "      <td>0.212467</td>\n",
       "      <td>0.176842</td>\n",
       "      <td>0.191438</td>\n",
       "      <td>0.228717</td>\n",
       "      <td>0.204544</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032061</td>\n",
       "      <td>0.596367</td>\n",
       "      <td>0.431174</td>\n",
       "      <td>-0.806450</td>\n",
       "      <td>0.848590</td>\n",
       "      <td>-0.041885</td>\n",
       "      <td>-2.126962</td>\n",
       "      <td>-2.239128</td>\n",
       "      <td>0.682263</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f2f18684-4a16-4c05-a2d1-c0f96d1de869</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1739.070423</td>\n",
       "      <td>0.248716</td>\n",
       "      <td>0.195947</td>\n",
       "      <td>0.207491</td>\n",
       "      <td>0.306865</td>\n",
       "      <td>0.243690</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157485</td>\n",
       "      <td>0.748673</td>\n",
       "      <td>0.277241</td>\n",
       "      <td>-0.695529</td>\n",
       "      <td>0.780302</td>\n",
       "      <td>0.153920</td>\n",
       "      <td>-2.096425</td>\n",
       "      <td>-2.357880</td>\n",
       "      <td>0.996960</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f852596d-fdca-45aa-9050-d4f76ce6a53c</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1420.266667</td>\n",
       "      <td>0.204193</td>\n",
       "      <td>0.172145</td>\n",
       "      <td>0.202812</td>\n",
       "      <td>0.227624</td>\n",
       "      <td>0.202849</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103053</td>\n",
       "      <td>0.636822</td>\n",
       "      <td>0.604018</td>\n",
       "      <td>-0.674785</td>\n",
       "      <td>0.877443</td>\n",
       "      <td>0.221118</td>\n",
       "      <td>-2.351851</td>\n",
       "      <td>-2.056856</td>\n",
       "      <td>0.768765</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f8ec3336-fd48-4654-ad98-62ccfb96d096</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2214.571429</td>\n",
       "      <td>0.244148</td>\n",
       "      <td>0.191466</td>\n",
       "      <td>0.207582</td>\n",
       "      <td>0.297661</td>\n",
       "      <td>0.237849</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190045</td>\n",
       "      <td>0.671676</td>\n",
       "      <td>0.389282</td>\n",
       "      <td>-0.605829</td>\n",
       "      <td>0.874221</td>\n",
       "      <td>0.093926</td>\n",
       "      <td>-2.235041</td>\n",
       "      <td>-2.297529</td>\n",
       "      <td>0.914307</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fb8de815-224c-4d06-9fd4-7156d1a9920d</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1572.806452</td>\n",
       "      <td>0.260739</td>\n",
       "      <td>0.231230</td>\n",
       "      <td>0.214622</td>\n",
       "      <td>0.257893</td>\n",
       "      <td>0.244366</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180165</td>\n",
       "      <td>0.750159</td>\n",
       "      <td>0.294824</td>\n",
       "      <td>-0.703003</td>\n",
       "      <td>0.756018</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>-1.988819</td>\n",
       "      <td>-2.349161</td>\n",
       "      <td>0.934187</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 318 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    code  response count  \\\n",
       "0   0031c86e-81f4-4eef-9e0e-28037abf9883            14.0   \n",
       "0   0225686d-b825-4cac-8691-3a3a5343df2b            18.0   \n",
       "0   041f950b-c013-409a-a642-cffff60b9d4b             9.0   \n",
       "0   04f91058-d0f8-4324-83b2-19c671f433dc            20.0   \n",
       "0   089eb66d-4c3a-4f58-b98f-a3774a2efb34            86.0   \n",
       "..                                   ...             ...   \n",
       "0   f24219d6-07f0-4baf-80ac-18475dc5b66f            21.0   \n",
       "0   f2f18684-4a16-4c05-a2d1-c0f96d1de869            71.0   \n",
       "0   f852596d-fdca-45aa-9050-d4f76ce6a53c            30.0   \n",
       "0   f8ec3336-fd48-4654-ad98-62ccfb96d096            14.0   \n",
       "0   fb8de815-224c-4d06-9fd4-7156d1a9920d            31.0   \n",
       "\n",
       "    avg. response length  top 1 fifth similarity  top 2 fifth similarity  \\\n",
       "0            2218.500000                0.228392                0.191977   \n",
       "0            1653.111111                0.241666                0.203096   \n",
       "0            1636.222222                0.214095                0.222064   \n",
       "0            1749.900000                0.316619                0.253115   \n",
       "0            1455.441860                0.322102                0.274355   \n",
       "..                   ...                     ...                     ...   \n",
       "0            1818.285714                0.212467                0.176842   \n",
       "0            1739.070423                0.248716                0.195947   \n",
       "0            1420.266667                0.204193                0.172145   \n",
       "0            2214.571429                0.244148                0.191466   \n",
       "0            1572.806452                0.260739                0.231230   \n",
       "\n",
       "    top 3 fifth similarity  top 4 fifth similarity  top 5 fifth similarity  \\\n",
       "0                 0.222714                0.252982                0.236511   \n",
       "0                 0.199066                0.258552                0.228758   \n",
       "0                 0.195110                0.198025                0.204584   \n",
       "0                 0.265028                0.346919                0.317167   \n",
       "0                 0.251310                0.300782                0.290301   \n",
       "..                     ...                     ...                     ...   \n",
       "0                 0.191438                0.228717                0.204544   \n",
       "0                 0.207491                0.306865                0.243690   \n",
       "0                 0.202812                0.227624                0.202849   \n",
       "0                 0.207582                0.297661                0.237849   \n",
       "0                 0.214622                0.257893                0.244366   \n",
       "\n",
       "    Q1 presence  Q2 presence  ...       291       292       293       294  \\\n",
       "0      0.004812     0.004353  ... -0.127357  0.718181  0.408075 -0.466869   \n",
       "0      0.003945     0.003034  ... -0.026360  0.877823  0.268821 -0.697356   \n",
       "0      0.003501     0.002800  ... -0.377180  0.958535  0.182306 -0.683194   \n",
       "0      0.003264     0.002975  ... -0.075040  0.877138  0.494181 -0.608385   \n",
       "0      0.000797     0.000484  ...  0.001565  0.906641  0.053110 -0.689573   \n",
       "..          ...          ...  ...       ...       ...       ...       ...   \n",
       "0      0.003023     0.002873  ...  0.032061  0.596367  0.431174 -0.806450   \n",
       "0      0.000783     0.000572  ... -0.157485  0.748673  0.277241 -0.695529   \n",
       "0      0.002008     0.002017  ...  0.103053  0.636822  0.604018 -0.674785   \n",
       "0      0.004056     0.003825  ... -0.190045  0.671676  0.389282 -0.605829   \n",
       "0      0.001979     0.001758  ... -0.180165  0.750159  0.294824 -0.703003   \n",
       "\n",
       "         295       296       297       298       299  grade  \n",
       "0   1.120409  0.290087 -2.362462 -2.166914  0.800465   48.0  \n",
       "0   0.702574 -0.085298 -2.083180 -2.442652  0.730275   99.0  \n",
       "0   0.959546  0.093472 -1.553406 -2.531710  1.012053   90.0  \n",
       "0   0.767160  0.088354 -2.170721 -2.184763  0.783525   97.0  \n",
       "0   0.772215 -0.106348 -1.679737 -2.382376  0.748501  100.0  \n",
       "..       ...       ...       ...       ...       ...    ...  \n",
       "0   0.848590 -0.041885 -2.126962 -2.239128  0.682263   93.0  \n",
       "0   0.780302  0.153920 -2.096425 -2.357880  0.996960  100.0  \n",
       "0   0.877443  0.221118 -2.351851 -2.056856  0.768765   98.0  \n",
       "0   0.874221  0.093926 -2.235041 -2.297529  0.914307  100.0  \n",
       "0   0.756018  0.007823 -1.988819 -2.349161  0.934187   98.0  \n",
       "\n",
       "[126 rows x 318 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for code, responses in code2responses.items():\n",
    "    studentRow = {i:[0] for i in ([\"code\",\"response count\",\"avg. response length\" ]+[\"top \"+str(l)+\" fifth similarity\" for l in range(1,6)]+[\"Q\"+str(k)+\" presence\" for k in range(1,10)]+[str(j) for j in range(300)]+[\"grade\"])}\n",
    "    \n",
    "    studentRow[\"code\"][0] = code\n",
    "    try:\n",
    "        studentRow[\"grade\"][0] = code2grade[code]\n",
    "    except:\n",
    "        continue\n",
    "    studentRow[\"response count\"][0] = len(responses)\n",
    "    try:\n",
    "        studentRow[\"avg. response length\"][0] = sum([len(i) for i in responses])/len(responses)\n",
    "    except:\n",
    "        studentRow[\"avg. response length\"][0] = 0\n",
    "    studentVector = np.zeros((300,))\n",
    "    for response in responses:\n",
    "        # clean the response \n",
    "        responseClean = response.lower().translate(str.maketrans('','',string.punctuation+\"\\n\"))\n",
    "\n",
    "        responseVector = spacynlp(responseClean).vector\n",
    "        \n",
    "        studentVector += responseVector / len(responses)\n",
    "        \n",
    "        for i in range(300):\n",
    "            studentRow[str(i)][0]+= responseVector[i]/len(responses)\n",
    "\n",
    "        \n",
    "        # measure similarity with questions \n",
    "        # (different versions are commented out to test performance of different similarity metrics and methods of recording similarity)\n",
    "        similarity = []\n",
    "        for question in range(9):\n",
    "            #studentRow[\"Q\"+str(question+1)+\" presence\"][0] = (1.0 - distance.cosine(responseVector, questionsVectorized[question])) / len(responses)\n",
    "            studentRow[\"Q\"+str(question+1)+\" presence\"][0] = (1.0 /(1+ distance.euclidean(responseVector, questionsVectorized[question]))) / len(responses)\n",
    "            \n",
    "            #similarity.append(1.0 - distance.cosine(responseVector, questionsVectorized[question]))\n",
    "            #similarity.append(1.0 /(1+ distance.euclidean(responseVector, questionsVectorized[question])))\n",
    "            \n",
    "        #qnum = np.array(similarity).argmax()+1\n",
    "        #studentRow[\"Q\"+str(qnum)+\" presence\"][0] += np.array(similarity).max()/len(responses)\n",
    "    \n",
    "    # measure similarity with representative vectors\n",
    "    # (different versions are commented out to test performance of different similarity metrics)\n",
    "    for k in range(5):\n",
    "        studentRow[\"top \"+str(k+1)+\" fifth similarity\"][0] = (1.0 /(1+ distance.euclidean(studentVector, pentileVectors[k])))\n",
    "        #studentRow[\"top \"+str(k+1)+\" fifth similarity\"][0] = (1.0 - distance.cosine(studentVector, pentileVectors[k]))\n",
    "    \n",
    "    studentRowFrame = pd.DataFrame(studentRow)\n",
    "    FinalDataFrame = pd.concat([FinalDataFrame, studentRowFrame])\n",
    "    \n",
    "\n",
    "\n",
    "FinalDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keyword analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139235c7-736c-4237-92f0-92e8c116832c\n",
      "668ad17e-0240-49f7-b5a7-d22e502554c6\n",
      "b0640e51-6879-40cb-a4f5-329f952ef99d\n",
      "da6b70d5-29f6-491a-ad46-037c77067128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>#user_prompts</th>\n",
       "      <th>#\\bhypothetical\\b</th>\n",
       "      <th>#warning</th>\n",
       "      <th>#error:</th>\n",
       "      <th>#wrong</th>\n",
       "      <th>#thank</th>\n",
       "      <th>#\\bentropy\\b</th>\n",
       "      <th>#\\bno\\b</th>\n",
       "      <th>#\\bpreprocess\\b</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0031c86e-81f4-4eef-9e0e-28037abf9883</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127357</td>\n",
       "      <td>0.718181</td>\n",
       "      <td>0.408075</td>\n",
       "      <td>-0.466869</td>\n",
       "      <td>1.120409</td>\n",
       "      <td>0.290087</td>\n",
       "      <td>-2.362462</td>\n",
       "      <td>-2.166914</td>\n",
       "      <td>0.800465</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0225686d-b825-4cac-8691-3a3a5343df2b</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026360</td>\n",
       "      <td>0.877823</td>\n",
       "      <td>0.268821</td>\n",
       "      <td>-0.697356</td>\n",
       "      <td>0.702574</td>\n",
       "      <td>-0.085298</td>\n",
       "      <td>-2.083180</td>\n",
       "      <td>-2.442652</td>\n",
       "      <td>0.730275</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>041f950b-c013-409a-a642-cffff60b9d4b</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.377180</td>\n",
       "      <td>0.958535</td>\n",
       "      <td>0.182306</td>\n",
       "      <td>-0.683194</td>\n",
       "      <td>0.959546</td>\n",
       "      <td>0.093472</td>\n",
       "      <td>-1.553406</td>\n",
       "      <td>-2.531710</td>\n",
       "      <td>1.012053</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04f91058-d0f8-4324-83b2-19c671f433dc</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075040</td>\n",
       "      <td>0.877138</td>\n",
       "      <td>0.494181</td>\n",
       "      <td>-0.608385</td>\n",
       "      <td>0.767160</td>\n",
       "      <td>0.088354</td>\n",
       "      <td>-2.170721</td>\n",
       "      <td>-2.184763</td>\n",
       "      <td>0.783525</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>089eb66d-4c3a-4f58-b98f-a3774a2efb34</td>\n",
       "      <td>86.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.906641</td>\n",
       "      <td>0.053110</td>\n",
       "      <td>-0.689573</td>\n",
       "      <td>0.772215</td>\n",
       "      <td>-0.106348</td>\n",
       "      <td>-1.679737</td>\n",
       "      <td>-2.382376</td>\n",
       "      <td>0.748501</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>f24219d6-07f0-4baf-80ac-18475dc5b66f</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032061</td>\n",
       "      <td>0.596367</td>\n",
       "      <td>0.431174</td>\n",
       "      <td>-0.806450</td>\n",
       "      <td>0.848590</td>\n",
       "      <td>-0.041885</td>\n",
       "      <td>-2.126962</td>\n",
       "      <td>-2.239128</td>\n",
       "      <td>0.682263</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>f2f18684-4a16-4c05-a2d1-c0f96d1de869</td>\n",
       "      <td>71.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157485</td>\n",
       "      <td>0.748673</td>\n",
       "      <td>0.277241</td>\n",
       "      <td>-0.695529</td>\n",
       "      <td>0.780302</td>\n",
       "      <td>0.153920</td>\n",
       "      <td>-2.096425</td>\n",
       "      <td>-2.357880</td>\n",
       "      <td>0.996960</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>f852596d-fdca-45aa-9050-d4f76ce6a53c</td>\n",
       "      <td>30.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103053</td>\n",
       "      <td>0.636822</td>\n",
       "      <td>0.604018</td>\n",
       "      <td>-0.674785</td>\n",
       "      <td>0.877443</td>\n",
       "      <td>0.221118</td>\n",
       "      <td>-2.351851</td>\n",
       "      <td>-2.056856</td>\n",
       "      <td>0.768765</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>f8ec3336-fd48-4654-ad98-62ccfb96d096</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190045</td>\n",
       "      <td>0.671676</td>\n",
       "      <td>0.389282</td>\n",
       "      <td>-0.605829</td>\n",
       "      <td>0.874221</td>\n",
       "      <td>0.093926</td>\n",
       "      <td>-2.235041</td>\n",
       "      <td>-2.297529</td>\n",
       "      <td>0.914307</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>fb8de815-224c-4d06-9fd4-7156d1a9920d</td>\n",
       "      <td>31.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180165</td>\n",
       "      <td>0.750159</td>\n",
       "      <td>0.294824</td>\n",
       "      <td>-0.703003</td>\n",
       "      <td>0.756018</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>-1.988819</td>\n",
       "      <td>-2.349161</td>\n",
       "      <td>0.934187</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     code  #user_prompts  #\\bhypothetical\\b  \\\n",
       "0    0031c86e-81f4-4eef-9e0e-28037abf9883           14.0               13.0   \n",
       "1    0225686d-b825-4cac-8691-3a3a5343df2b           18.0                6.0   \n",
       "2    041f950b-c013-409a-a642-cffff60b9d4b            9.0                8.0   \n",
       "3    04f91058-d0f8-4324-83b2-19c671f433dc           20.0                3.0   \n",
       "4    089eb66d-4c3a-4f58-b98f-a3774a2efb34           86.0               11.0   \n",
       "..                                    ...            ...                ...   \n",
       "118  f24219d6-07f0-4baf-80ac-18475dc5b66f           21.0                0.0   \n",
       "119  f2f18684-4a16-4c05-a2d1-c0f96d1de869           71.0               16.0   \n",
       "120  f852596d-fdca-45aa-9050-d4f76ce6a53c           30.0               68.0   \n",
       "121  f8ec3336-fd48-4654-ad98-62ccfb96d096           14.0               14.0   \n",
       "122  fb8de815-224c-4d06-9fd4-7156d1a9920d           31.0               14.0   \n",
       "\n",
       "     #warning  #error:  #wrong  #thank  #\\bentropy\\b  #\\bno\\b  \\\n",
       "0         0.0      2.0     0.0     0.0           0.0      1.0   \n",
       "1         0.0      0.0     0.0     0.0          25.0      0.0   \n",
       "2         0.0      5.0     0.0     1.0          53.0      0.0   \n",
       "3         0.0      2.0     0.0     0.0          34.0      1.0   \n",
       "4         0.0      4.0     1.0     1.0         168.0      5.0   \n",
       "..        ...      ...     ...     ...           ...      ...   \n",
       "118       0.0      0.0     0.0     1.0          81.0      0.0   \n",
       "119       0.0      3.0     0.0     2.0          51.0      1.0   \n",
       "120       0.0      6.0     0.0     0.0          48.0      1.0   \n",
       "121       0.0      0.0     0.0     0.0          34.0      0.0   \n",
       "122       7.0     12.0     1.0     2.0          50.0      0.0   \n",
       "\n",
       "     #\\bpreprocess\\b  ...       291       292       293       294       295  \\\n",
       "0                1.0  ... -0.127357  0.718181  0.408075 -0.466869  1.120409   \n",
       "1                0.0  ... -0.026360  0.877823  0.268821 -0.697356  0.702574   \n",
       "2                0.0  ... -0.377180  0.958535  0.182306 -0.683194  0.959546   \n",
       "3                0.0  ... -0.075040  0.877138  0.494181 -0.608385  0.767160   \n",
       "4                0.0  ...  0.001565  0.906641  0.053110 -0.689573  0.772215   \n",
       "..               ...  ...       ...       ...       ...       ...       ...   \n",
       "118              0.0  ...  0.032061  0.596367  0.431174 -0.806450  0.848590   \n",
       "119              1.0  ... -0.157485  0.748673  0.277241 -0.695529  0.780302   \n",
       "120              0.0  ...  0.103053  0.636822  0.604018 -0.674785  0.877443   \n",
       "121              0.0  ... -0.190045  0.671676  0.389282 -0.605829  0.874221   \n",
       "122              0.0  ... -0.180165  0.750159  0.294824 -0.703003  0.756018   \n",
       "\n",
       "          296       297       298       299  grade  \n",
       "0    0.290087 -2.362462 -2.166914  0.800465   48.0  \n",
       "1   -0.085298 -2.083180 -2.442652  0.730275   99.0  \n",
       "2    0.093472 -1.553406 -2.531710  1.012053   90.0  \n",
       "3    0.088354 -2.170721 -2.184763  0.783525   97.0  \n",
       "4   -0.106348 -1.679737 -2.382376  0.748501  100.0  \n",
       "..        ...       ...       ...       ...    ...  \n",
       "118 -0.041885 -2.126962 -2.239128  0.682263   93.0  \n",
       "119  0.153920 -2.096425 -2.357880  0.996960  100.0  \n",
       "120  0.221118 -2.351851 -2.056856  0.768765   98.0  \n",
       "121  0.093926 -2.235041 -2.297529  0.914307  100.0  \n",
       "122  0.007823 -1.988819 -2.349161  0.934187   98.0  \n",
       "\n",
       "[123 rows x 334 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code2features = defaultdict(lambda : defaultdict(int))\n",
    "keywords2search_p = [r'\\bhypothetical\\b', r'warning', r'error:', r'wrong', r'thank', r'\\bentropy\\b', r'\\bno\\b', r'\\bpreprocess\\b', r'hyperparameters', r're-train', r'\\w?health_metrics\\w?', r'how']\n",
    "keywords2search_r = [r'thank', r'\\bhypothetical\\b', r'\\bentropy\\b', r'apologize', r'\\bmissing\\b', r'hyperparameters', r'\\w?health_metrics\\w?']\n",
    "\n",
    "for code, convs in code2convos.items():\n",
    "    if len(convs) == 0:\n",
    "        print(code)\n",
    "        continue\n",
    "    for c in convs:\n",
    "        text = c[\"text\"].lower()\n",
    "        if c[\"role\"] == \"user\":\n",
    "            # User Prompts\n",
    "\n",
    "            # count the user prompts\n",
    "            code2features[code][\"#user_prompts\"] += 1\n",
    "            \n",
    "            # count the keywords\n",
    "            for kw in keywords2search_p:\n",
    "                code2features[code][f\"#{kw}\"] +=  len(re.findall(kw, text))\n",
    "\n",
    "            code2features[code][\"prompt_avg_chars\"] += len(text)\n",
    "        else:\n",
    "            # ChatGPT Responses\n",
    "\n",
    "            # count the keywords\n",
    "            for kw in keywords2search_r:\n",
    "                code2features[code][f\"#{kw}\"] +=  len(re.findall(kw, text))\n",
    "\n",
    "        code2features[code][\"prompt_avg_chars\"] /= code2features[code][\"#user_prompts\"]   \n",
    "df = pd.DataFrame(code2features).T\n",
    "df.head(5)\n",
    "df.reset_index(inplace=True, drop=False)\n",
    "df.rename(columns={\"index\": \"code\"}, inplace=True)\n",
    "df.head()\n",
    "FinalDataFrame = pd.merge(df, FinalDataFrame, on=\"code\", how=\"left\")\n",
    "FinalDataFrame.fillna(0, inplace=True)\n",
    "FinalDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculated features are introduced into the dataframe here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grade                    1.000000\n",
      "prompt_avg_chars         0.363722\n",
      "Q5 presence              0.318202\n",
      "Q3 presence              0.297784\n",
      "combined_questions       0.285723\n",
      "Q8 presence              0.283698\n",
      "Q6 presence              0.277607\n",
      "Q7 presence              0.276563\n",
      "Q1 presence              0.273892\n",
      "Q4 presence              0.269119\n",
      "Q2 presence              0.262354\n",
      "Q9 presence              0.259471\n",
      "response count           0.225545\n",
      "combined_chat_stats      0.224157\n",
      "combined_kw              0.170818\n",
      "#user_prompts            0.162624\n",
      "#thank                   0.154763\n",
      "#\\w?health_metrics\\w?    0.152238\n",
      "#re-train                0.114495\n",
      "#\\bpreprocess\\b          0.114228\n",
      "#\\bmissing\\b             0.107345\n",
      "#wrong                   0.106384\n",
      "#\\bno\\b                  0.103511\n",
      "#apologize               0.093068\n",
      "#warning                 0.074610\n",
      "#\\bentropy\\b             0.072700\n",
      "#\\bhypothetical\\b        0.071749\n",
      "#hyperparameters         0.060051\n",
      "avg. response length     0.049112\n",
      "#how                     0.048860\n",
      "#error:                  0.043577\n",
      "Name: grade, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "shuffledFrame = shuffle(FinalDataFrame.drop(columns=[str(j) for j in range(300)]+[\"top \"+str(k+1)+\" fifth similarity\" for k in range(5)]), random_state=42)\n",
    "\n",
    "# Optimized feature selection:\n",
    "\n",
    "# Combined chat stats\n",
    "shuffledFrame['combined_chat_stats'] = shuffledFrame['prompt_avg_chars'] * shuffledFrame['#user_prompts'] + shuffledFrame['response count'] * shuffledFrame['avg. response length']\n",
    "shuffledFrame['combined_chat_stats'].fillna(0, inplace=True)\n",
    "# Combined questions\n",
    "shuffledFrame['combined_questions'] = shuffledFrame['Q1 presence'] + shuffledFrame['Q2 presence'] + shuffledFrame['Q3 presence'] + shuffledFrame['Q4 presence'] + shuffledFrame['Q5 presence'] + shuffledFrame['Q6 presence'] + shuffledFrame['Q7 presence'] + shuffledFrame['Q8 presence'] + shuffledFrame['Q9 presence']\n",
    "# Combined keywords feature\n",
    "shuffledFrame['combined_kw'] = shuffledFrame['#user_prompts'] + shuffledFrame['#thank'] + shuffledFrame['#\\w?health_metrics\\w?'] + shuffledFrame['#re-train'] + shuffledFrame['#\\\\bpreprocess\\\\b'] + shuffledFrame['#\\\\bmissing\\\\b'] + shuffledFrame['#wrong'] + shuffledFrame['#\\\\bno\\\\b']\n",
    "\n",
    "# Calculate the correlation matrix between the features and the target variable\n",
    "corr_matrix = shuffledFrame.drop(columns=['code']).corr().abs()\n",
    "# Print the correlations in decreasing order\n",
    "print(corr_matrix['grade'].sort_values(ascending=False))\n",
    "\n",
    "Xframe = shuffledFrame.drop(columns=['code','grade'])\n",
    "Yframe = shuffledFrame['grade']\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(Xframe, Yframe, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 1: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train: 0.1825396825396825\n",
      "MSE TEST: 83.47632716049382\n",
      "R2 Train: 0.9993082846265403\n",
      "R2 TEST: -2.6070730417110504\n"
     ]
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor(random_state=0,criterion='squared_error', max_depth=10)\n",
    "regressor.fit(train_data, train_labels)\n",
    "\n",
    "# Prediction\n",
    "y_train_pred = regressor.predict(train_data)\n",
    "y_test_pred = regressor.predict(test_data)\n",
    "\n",
    "# Calculation of Mean Squared Error (MSE)\n",
    "print(\"MSE Train:\", mean_squared_error(train_labels,y_train_pred))\n",
    "print(\"MSE TEST:\", mean_squared_error(test_labels,y_test_pred))\n",
    "\n",
    "print(\"R2 Train:\", r2_score(train_labels,y_train_pred))\n",
    "print(\"R2 TEST:\", r2_score(test_labels,y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
